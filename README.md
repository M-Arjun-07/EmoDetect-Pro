# EmoDetect-Pro
Emotion Recognition from Face is a Computer Vision and Deep Learning project that detects human emotions from facial expressions using a Convolutional Neural Network (CNN).

## Explainable Emotion Recognition from Face using CNN

An advanced Explainable AI (XAI) based Emotion Recognition System that detects human emotions from facial expressions using Deep Learning and visualizes internal CNN operations.

This project is not just a classifier â€” it is a complete educational + deployment-ready AI system.

---

# ğŸ“Œ Project Overview

This system:

- Detects human emotions from facial images
- Uses Convolutional Neural Networks (CNN)
- Works as:
  - ğŸŒ Web Application (Flask)
  - ğŸ–¥ Desktop Application (Tkinter)
- Visualizes:
  - Convolution Feature Maps
  - Pooling Outputs
  - Softmax Probability Distribution
- Supports Real-Time Webcam Emotion Detection

---

# ğŸ§  Technical Domain

Artificial Intelligence  
â†’ Machine Learning  
â†’ Deep Learning  
â†’ Convolutional Neural Networks  
â†’ Computer Vision  
â†’ Emotion Recognition  

---

# ğŸ“‚ Dataset

Dataset Used: **FER2013**

### Dataset Properties:
- 48x48 grayscale facial images
- 7 emotion classes:
  - Angry
  - Disgust
  - Fear
  - Happy
  - Sad
  - Surprise
  - Neutral

### Preprocessing Steps:
- Convert pixel strings to image arrays
- Reshape to (48, 48, 1)
- Normalize pixel values (divide by 255)
- One-hot encode labels
- Handle class imbalance (if required)

---

# ğŸ— System Architecture

```
Input Image / Webcam
        â†“
Face Detection (OpenCV Haar Cascade)
        â†“
Crop Face Region
        â†“
Resize to 48x48
        â†“
Convert to Grayscale
        â†“
Normalize (0â€“1)
        â†“
CNN Model
        â†“
Extract Intermediate Layer Outputs
        â†“
Visualization Dashboard
        â†“
Final Emotion Prediction
```

---

# ğŸ§© CNN Model Architecture

```
Layer 1:
Conv2D (32 filters, 3x3) â†’ ReLU â†’ MaxPooling (2x2)

Layer 2:
Conv2D (64 filters, 3x3) â†’ ReLU â†’ MaxPooling (2x2)

Layer 3:
Conv2D (128 filters, 3x3) â†’ ReLU â†’ MaxPooling (2x2)

Flatten

Dense (128) â†’ ReLU
Dropout (0.5)

Output Layer:
Dense (7) â†’ Softmax
```

### Model Compilation
- Loss: Categorical Crossentropy
- Optimizer: Adam
- Metric: Accuracy

### Expected Accuracy
- Basic CNN: 65â€“70%
- Improved CNN: 70â€“75%
- Transfer Learning: 75â€“85%

---

# ğŸ“Š Explainable AI Features

This project visualizes:

1. Convolution Feature Maps  
2. Pooling Outputs  
3. Softmax Probability Bar Graph  
4. Intermediate Layer Activations  

This makes the system educational and interpretable.

---

# ğŸš€ Features

âœ… Emotion Detection from Images  
âœ… Real-Time Webcam Detection  
âœ… CNN Internal Visualization  
âœ… Web-based Interface (Flask)  
âœ… Desktop GUI (Tkinter)  
âœ… Model Evaluation Metrics  
âœ… Ready for Deployment  

---

# ğŸ—‚ Project Structure

```
emotion-vision-system/
â”‚
â”œâ”€â”€ dataset/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ emotion_model.h5
â”‚
â”œâ”€â”€ static/
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ visualize.py
â”œâ”€â”€ real_time.py
â”œâ”€â”€ app.py
â”œâ”€â”€ index.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ›  Technologies Used

| Category | Tools |
|----------|--------|
| Programming | Python |
| Deep Learning | TensorFlow / Keras |
| Computer Vision | OpenCV |
| Data Handling | NumPy, Pandas |
| Visualization | Matplotlib, Seaborn |
| Web Framework | Flask |
| Desktop GUI | Tkinter |

---

# ğŸ”¬ Model Development Process

## 1ï¸âƒ£ Data Preprocessing
- Load FER2013 dataset
- Convert pixel strings to arrays
- Normalize pixel values
- Reshape images
- Split into train/test sets

## 2ï¸âƒ£ Model Training
- Epochs: 30â€“50
- Batch Size: 32
- Validation Split used
- Save trained model to `models/emotion_model.h5`

## 3ï¸âƒ£ Model Evaluation
- Accuracy
- Confusion Matrix
- Precision
- Recall
- F1 Score

## 4ï¸âƒ£ Real-Time Emotion Detection
- Capture webcam feed
- Detect face using OpenCV
- Preprocess face image
- Predict emotion
- Display emotion label on screen

---

# ğŸ“ˆ Advanced Improvements

- Data Augmentation (Rotation, Flip, Zoom)
- Hyperparameter Tuning
- Transfer Learning (MobileNet, ResNet)
- Model Comparison Experiments
- Cloud Deployment (AWS / Render)

---

# ğŸ“… Development Roadmap

### Phase 1 â€“ Dataset Mastery
- Load and preprocess FER2013
- Perform Exploratory Data Analysis (EDA)

### Phase 2 â€“ Baseline CNN
- Build first working model
- Train and evaluate

### Phase 3 â€“ Visualization Module
- Extract intermediate layer outputs
- Display feature maps
- Plot softmax probabilities

### Phase 4 â€“ Deployment
- Build Flask Web App
- Build Tkinter Desktop App
- Integrate Webcam Detection

---

# ğŸ¯ Interview Preparation

Be ready to answer:

- Why CNN for image tasks?
- What is overfitting?
- Why use dropout?
- Why softmax in output layer?
- What is categorical crossentropy?
- How did you improve model accuracy?
- What challenges did FER2013 dataset present?

---

# ğŸ“ Learning Outcomes

After completing this project, you will:

- Understand CNN deeply
- Build real-time AI pipelines
- Implement Explainable AI systems
- Train and evaluate deep learning models
- Deploy AI applications
- Create a strong resume-level AI project

---

# ğŸ’¡ Project Tagline

"Building an Explainable AI Emotion Recognition System with Real-Time CNN Visualization."
